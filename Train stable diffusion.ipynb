{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"16oldki5GwaDcRf-DBUJLs0qioD3SyZzt","timestamp":1752587050960}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#Dataset: https://huggingface.co/datasets/AdamLucek/oldbookillustrations-small"],"metadata":{"id":"HjaqJELZC94r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Model:https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5"],"metadata":{"id":"XmyAHD1JDB0h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Load Gdrive"],"metadata":{"id":"qyeXy0oYP_0I"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=True)"],"metadata":{"id":"KCTRXXFlP_go","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752646848567,"user_tz":-420,"elapsed":6817,"user":{"displayName":"Lâm Đức Cương","userId":"02362263444637620675"}},"outputId":"52088400-473b-4781-a48b-0b9041c6b738"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# Install dependecies"],"metadata":{"id":"DGlmnoScQteT"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"WCcYh92sP96K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752588026169,"user_tz":-420,"elapsed":89351,"user":{"displayName":"Lâm Đức Cương","userId":"02362263444637620675"}},"outputId":"2dc821a0-5e97-4b45-9fd7-7c87458bbfce"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting bitsandbytes\n","  Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n","Requirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.14.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2025.3.2)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.2->bitsandbytes)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.2->bitsandbytes)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.2->bitsandbytes)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.2->bitsandbytes)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.2->bitsandbytes)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.2->bitsandbytes)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n","Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl (72.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m120.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m106.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed bitsandbytes-0.46.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"]}],"source":["!pip install bitsandbytes"]},{"cell_type":"code","source":["!pip install -q accelerate transformers ftfy tensorboard Jinja2 peft --upgrade"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s6984PQrTJ4V","executionInfo":{"status":"ok","timestamp":1752588043530,"user_tz":-420,"elapsed":17341,"user":{"displayName":"Lâm Đức Cương","userId":"02362263444637620675"}},"outputId":"02e63f21-db5d-439e-bb85-6c00e60bbdcc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.18.0 requires tensorboard<2.19,>=2.18, but you have tensorboard 2.19.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["!pip install -q git+https://github.com/huggingface/diffusers.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HtPR06e3Tb2t","executionInfo":{"status":"ok","timestamp":1752588063460,"user_tz":-420,"elapsed":19915,"user":{"displayName":"Lâm Đức Cương","userId":"02362263444637620675"}},"outputId":"0bf2c441-f191-45b8-9433-7af23ce547b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"markdown","source":["# Train"],"metadata":{"id":"wVc-zLSpQwJQ"}},{"cell_type":"code","source":["# !wget https://raw.githubusercontent.com/RaffelRavionaldo/Stable-diffusion/main/train/train_dreambooth_2.py -O /content/drive/MyDrive/train_dreambooth_2.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lXVNqkTyacPd","executionInfo":{"status":"ok","timestamp":1752588472299,"user_tz":-420,"elapsed":292,"user":{"displayName":"Lâm Đức Cương","userId":"02362263444637620675"}},"outputId":"1e401f24-84e2-48c4-b636-5ac3f74d920a","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2025-07-15 14:07:51--  https://raw.githubusercontent.com/RaffelRavionaldo/Stable-diffusion/main/train/train_dreambooth_2.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 61665 (60K) [text/plain]\n","Saving to: ‘/content/drive/MyDrive/train_dreambooth_2.py’\n","\n","\r          /content/   0%[                    ]       0  --.-KB/s               \r/content/drive/MyDr 100%[===================>]  60.22K  --.-KB/s    in 0.009s  \n","\n","2025-07-15 14:07:52 (6.47 MB/s) - ‘/content/drive/MyDrive/train_dreambooth_2.py’ saved [61665/61665]\n","\n"]}]},{"cell_type":"code","source":["import os\n","import shutil\n","\n","# Đường dẫn ảnh và caption gốc\n","image_dir = \"/content/drive/MyDrive/oldbookillustrations-small/images\"\n","caption_dir = \"/content/drive/MyDrive/oldbookillustrations-small/captions\"\n","\n","# Đường dẫn đích theo định dạng DreamBoothDataset\n","output_dir = \"/content/drive/MyDrive/oldbookillustrations-dataset/instance_data_root/default\"\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# Duyệt và sao chép từng ảnh và caption tương ứng\n","count = 0\n","for filename in sorted(os.listdir(image_dir)):\n","    if filename.endswith((\".png\", \".jpg\", \".jpeg\")):\n","        img_path = os.path.join(image_dir, filename)\n","        caption_path = os.path.join(caption_dir, os.path.splitext(filename)[0] + \".txt\")\n","\n","        dst_img_path = os.path.join(output_dir, filename)\n","        dst_txt_path = os.path.join(output_dir, os.path.splitext(filename)[0] + \".txt\")\n","\n","        shutil.copyfile(img_path, dst_img_path)\n","        if os.path.exists(caption_path):\n","            shutil.copyfile(caption_path, dst_txt_path)\n","        else:\n","            print(f\"⚠️ Không tìm thấy caption cho ảnh: {filename}\")\n","\n","        count += 1\n","\n","print(f\"✅ Đã sao chép {count} ảnh và caption vào {output_dir}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LitB9tSQfXb8","executionInfo":{"status":"ok","timestamp":1752590313168,"user_tz":-420,"elapsed":549815,"user":{"displayName":"Lâm Đức Cương","userId":"02362263444637620675"}},"outputId":"d730dffd-2ac1-4d1a-ad05-dd2cd0384ec7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Đã sao chép 1000 ảnh và caption vào /content/drive/MyDrive/oldbookillustrations-dataset/instance_data_root/default\n"]}]},{"cell_type":"code","source":["# Đường dẫn cho class_data_root\n","class_dir = \"/content/drive/MyDrive/oldbookillustrations-dataset/class_data_root/default\"\n","os.makedirs(class_dir, exist_ok=True)\n","\n","# Prompt chung cho class\n","class_prompt = \"A vintage book illustration\"\n","\n","# Tạo file classes.txt\n","with open(os.path.join(class_dir, \"classes.txt\"), \"w\", encoding=\"utf-8\") as f:\n","    f.write(class_prompt)\n","\n","# Lấy 10 ảnh đầu từ instance làm ảnh class\n","instance_images = sorted(os.listdir(output_dir))\n","image_count = 0\n","for fname in instance_images:\n","    if fname.endswith((\".png\", \".jpg\", \".jpeg\")):\n","        src = os.path.join(output_dir, fname)\n","        dst = os.path.join(class_dir, f\"class_{fname}\")\n","        shutil.copyfile(src, dst)\n","        image_count += 1\n","        if image_count >= 10:\n","            break\n","\n","print(f\"✅ Đã tạo {image_count} ảnh class trong {class_dir}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C8COzdu2feNd","executionInfo":{"status":"ok","timestamp":1752590321473,"user_tz":-420,"elapsed":302,"user":{"displayName":"Lâm Đức Cương","userId":"02362263444637620675"}},"outputId":"e1162eeb-aedc-4dc9-a85b-7c30a6048c56"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Đã tạo 10 ảnh class trong /content/drive/MyDrive/oldbookillustrations-dataset/class_data_root/default\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","caption_csv = \"/content/drive/MyDrive/oldbookillustrations-small/captions.csv\"\n","df = pd.read_csv(caption_csv)\n","\n","print(df.columns)  # In ra tên các cột thật sự\n","df.head()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":223},"id":"bPcP2z2XdP0e","executionInfo":{"status":"ok","timestamp":1752589207731,"user_tz":-420,"elapsed":44,"user":{"displayName":"Lâm Đức Cương","userId":"02362263444637620675"}},"outputId":"818c8e9d-ad37-4b91-ac43-6035a9299fff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['filename', 'caption'], dtype='object')\n"]},{"output_type":"execute_result","data":{"text/plain":["    filename                                            caption\n","0  00000.png  A bald man with a long beard smiles faintly as...\n","1  00001.png  Dante stumbles against the traitor Bocca degli...\n","2  00002.png  View of the Arno at Florence with a section of...\n","3  00003.png  Terracotta vase with foliated ornaments and fi...\n","4  00004.png  A family can be seen next to a holy water basi..."],"text/html":["\n","  <div id=\"df-98a0148e-df93-4fa8-b8a8-1639458c6b36\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>filename</th>\n","      <th>caption</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>00000.png</td>\n","      <td>A bald man with a long beard smiles faintly as...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>00001.png</td>\n","      <td>Dante stumbles against the traitor Bocca degli...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>00002.png</td>\n","      <td>View of the Arno at Florence with a section of...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>00003.png</td>\n","      <td>Terracotta vase with foliated ornaments and fi...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>00004.png</td>\n","      <td>A family can be seen next to a holy water basi...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98a0148e-df93-4fa8-b8a8-1639458c6b36')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-98a0148e-df93-4fa8-b8a8-1639458c6b36 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-98a0148e-df93-4fa8-b8a8-1639458c6b36');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-2a74591e-d6ab-4990-b8fe-7ef41dcb77db\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2a74591e-d6ab-4990-b8fe-7ef41dcb77db')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-2a74591e-d6ab-4990-b8fe-7ef41dcb77db button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"filename\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"00521.png\",\n          \"00737.png\",\n          \"00740.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"caption\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 998,\n        \"samples\": [\n          \"A woman is led by a veiled figure through a place with bodies tied to pillars\",\n          \"Jugglers and acrobats at the castle\",\n          \"Flower and leaves of Gardenia jasminoides var fortuneana an evergreen shrub native to Asia\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["!accelerate launch /content/drive/MyDrive/train_dreambooth_2.py \\\n","  --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" \\\n","  --instance_data_dir=\"/content/drive/MyDrive/oldbookillustrations-dataset/instance_data_root\" \\\n","  --output_dir=\"/content/drive/MyDrive/oldbookillustrations-dataset/model_output\" \\\n","  --instance_prompt=\"a photo of [V*]\" \\\n","  --class_prompt=\"A vintage book illustration\" \\\n","  --class_data_dir=\"/content/drive/MyDrive/oldbookillustrations-dataset/class_data_root\" \\\n","  --resolution=512 \\\n","  --train_batch_size=1 \\\n","  --learning_rate=2e-6 \\\n","  --lr_scheduler=\"constant\" \\\n","  --max_train_steps=4000 \\\n","  --mixed_precision=\"fp16\" \\\n","  --checkpointing_steps=2000 \\\n","  --use_8bit_adam \\\n","  --gradient_checkpointing \\\n","  --with_prior_preservation \\\n","  --train_text_encoder\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VGq41KKgiVYC","executionInfo":{"status":"ok","timestamp":1752597209361,"user_tz":-420,"elapsed":1666033,"user":{"displayName":"Lâm Đức Cương","userId":"02362263444637620675"}},"outputId":"ec80dc9e-2df9-4163-8b7b-775afb395475"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.\n","The following values were not passed to `accelerate launch` and had defaults used instead:\n","\t`--num_processes` was set to a value of `1`\n","\t`--num_machines` was set to a value of `1`\n","\t`--mixed_precision` was set to a value of `'no'`\n","\t`--dynamo_backend` was set to a value of `'no'`\n","To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n","2025-07-15 14:46:49.731451: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1752590810.004934   15707 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1752590810.072786   15707 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-07-15 14:46:50.664780: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","model_index.json: 100% 541/541 [00:00<00:00, 3.20MB/s]\n","Fetching 13 files:   0% 0/13 [00:00<?, ?it/s]\n","preprocessor_config.json: 100% 342/342 [00:00<00:00, 2.60MB/s]\n","\n","config.json: 100% 617/617 [00:00<00:00, 5.74MB/s]\n","\n","special_tokens_map.json: 100% 472/472 [00:00<00:00, 495kB/s]\n","\n","merges.txt: 0.00B [00:00, ?B/s]\u001b[A\n","\n","tokenizer_config.json: 100% 806/806 [00:00<00:00, 7.92MB/s]\n","\n","\n","vocab.json: 0.00B [00:00, ?B/s]\u001b[A\u001b[A\n","\n","\n","scheduler_config.json: 100% 308/308 [00:00<00:00, 2.85MB/s]\n","merges.txt: 525kB [00:00, 17.6MB/s]\n","vocab.json: 1.06MB [00:00, 27.7MB/s]\n","\n","model.safetensors:   0% 0.00/492M [00:00<?, ?B/s]\u001b[A\n","\n","config.json: 100% 743/743 [00:00<00:00, 6.43MB/s]\n","\n","\n","config.json: 100% 547/547 [00:00<00:00, 3.78MB/s]\n","\n","\n","diffusion_pytorch_model.safetensors:   0% 0.00/335M [00:00<?, ?B/s]\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:   0% 0.00/3.44G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n","model.safetensors:   2% 10.5M/492M [00:00<00:16, 29.6MB/s]\u001b[A\n","model.safetensors:   4% 21.0M/492M [00:00<00:10, 46.8MB/s]\u001b[A\n","\n","diffusion_pytorch_model.safetensors:   3% 10.5M/335M [00:00<00:09, 32.6MB/s]\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:   0% 10.5M/3.44G [00:00<01:51, 30.7MB/s]\u001b[A\u001b[A\u001b[A\n","model.safetensors:   6% 31.5M/492M [00:00<00:08, 57.4MB/s]\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:   1% 21.0M/3.44G [00:00<01:06, 51.3MB/s]\u001b[A\u001b[A\u001b[A\n","\n","diffusion_pytorch_model.safetensors:   9% 31.5M/335M [00:00<00:04, 66.8MB/s]\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:   1% 31.5M/3.44G [00:00<00:52, 64.5MB/s]\u001b[A\u001b[A\u001b[A\n","model.safetensors:   9% 41.9M/492M [00:00<00:07, 62.9MB/s]\u001b[A\n","\n","diffusion_pytorch_model.safetensors:  13% 41.9M/335M [00:00<00:03, 75.2MB/s]\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:   1% 41.9M/3.44G [00:00<00:49, 68.9MB/s]\u001b[A\u001b[A\u001b[A\n","model.safetensors:  11% 52.4M/492M [00:00<00:06, 65.3MB/s]\u001b[A\n","\n","diffusion_pytorch_model.safetensors:  16% 52.4M/335M [00:00<00:03, 76.1MB/s]\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:   2% 52.4M/3.44G [00:00<00:45, 74.6MB/s]\u001b[A\u001b[A\u001b[A\n","\n","diffusion_pytorch_model.safetensors:  19% 62.9M/335M [00:00<00:03, 81.1MB/s]\u001b[A\u001b[A\n","model.safetensors:  13% 62.9M/492M [00:01<00:06, 63.4MB/s]\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:   2% 62.9M/3.44G [00:00<00:42, 78.7MB/s]\u001b[A\u001b[A\u001b[A\n","\n","diffusion_pytorch_model.safetensors:  22% 73.4M/335M [00:00<00:02, 87.1MB/s]\u001b[A\u001b[A\n","model.safetensors:  15% 73.4M/492M [00:01<00:06, 67.2MB/s]\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:   2% 73.4M/3.44G [00:01<00:42, 78.4MB/s]\u001b[A\u001b[A\u001b[A\n","\n","diffusion_pytorch_model.safetensors:  25% 83.9M/335M [00:01<00:02, 87.1MB/s]\u001b[A\u001b[A\n","model.safetensors:  17% 83.9M/492M [00:01<00:05, 69.2MB/s]\u001b[A\n","\n","diffusion_pytorch_model.safetensors:  28% 94.4M/335M [00:01<00:02, 89.7MB/s]\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:   2% 83.9M/3.44G [00:01<00:43, 76.9MB/s]\u001b[A\u001b[A\u001b[A\n","\n","diffusion_pytorch_model.safetensors:  31% 105M/335M [00:01<00:02, 93.0MB/s] \u001b[A\u001b[A\n","model.safetensors:  19% 94.4M/492M [00:01<00:05, 72.0MB/s]\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:   3% 94.4M/3.44G [00:01<00:44, 75.8MB/s]\u001b[A\u001b[A\u001b[A\n","\n","diffusion_pytorch_model.safetensors:  34% 115M/335M [00:01<00:02, 88.3MB/s]\u001b[A\u001b[A\n","model.safetensors:  21% 105M/492M [00:01<00:05, 70.2MB/s] \u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:   3% 105M/3.44G [00:01<00:43, 77.4MB/s] \u001b[A\u001b[A\u001b[A\n","\n","diffusion_pytorch_model.safetensors:  38% 126M/335M [00:01<00:02, 90.2MB/s]\u001b[A\u001b[A\n","model.safetensors:  23% 115M/492M [00:01<00:05, 71.6MB/s]\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:   3% 115M/3.44G [00:01<00:42, 78.1MB/s]\u001b[A\u001b[A\u001b[A\n","\n","diffusion_pytorch_model.safetensors:  41% 136M/335M [00:01<00:02, 91.5MB/s]\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:   4% 126M/3.44G [00:01<00:39, 83.1MB/s]\u001b[A\u001b[A\u001b[A\n","\n","diffusion_pytorch_model.safetensors:  44% 147M/335M [00:01<00:01, 94.9MB/s]\u001b[A\u001b[A\n","model.safetensors:  26% 126M/492M [00:01<00:05, 69.8MB/s]\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:   4% 136M/3.44G [00:01<00:37, 87.6MB/s]\u001b[A\u001b[A\u001b[A\n","\n","diffusion_pytorch_model.safetensors:  47% 157M/335M [00:01<00:01, 96.6MB/s]\u001b[A\u001b[A\n","model.safetensors:  28% 136M/492M [00:02<00:05, 69.4MB/s]\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:   4% 147M/3.44G [00:01<00:36, 89.6MB/s]\u001b[A\u001b[A\u001b[A\n","\n","diffusion_pytorch_model.safetensors:  50% 168M/335M [00:01<00:01, 95.1MB/s]\u001b[A\u001b[A\n","model.safetensors:  30% 147M/492M [00:02<00:04, 72.2MB/s]\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:   5% 157M/3.44G [00:02<00:37, 87.8MB/s]\u001b[A\u001b[A\u001b[A\n","\n","diffusion_pytorch_model.safetensors:  53% 178M/335M [00:02<00:01, 96.8MB/s]\u001b[A\u001b[A\n","\n","diffusion_pytorch_model.safetensors:  56% 189M/335M [00:02<00:01, 97.9MB/s]\u001b[A\u001b[A\n","model.safetensors:  32% 157M/492M [00:02<00:04, 71.5MB/s]\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:   5% 168M/3.44G [00:02<00:39, 81.9MB/s]\u001b[A\u001b[A\u001b[A\n","\n","diffusion_pytorch_model.safetensors:  60% 199M/335M [00:02<00:01, 94.0MB/s]\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:   5% 178M/3.44G [00:02<00:38, 84.9MB/s]\u001b[A\u001b[A\u001b[A\n","model.safetensors:  34% 168M/492M [00:02<00:04, 70.9MB/s]\u001b[A\n","\n","diffusion_pytorch_model.safetensors:  63% 210M/335M [00:02<00:01, 92.5MB/s]\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:   5% 189M/3.44G [00:02<00:37, 87.3MB/s]\u001b[A\u001b[A\u001b[A\n","model.safetensors:  36% 178M/492M [00:02<00:04, 73.0MB/s]\u001b[A\n","\n","diffusion_pytorch_model.safetensors:  66% 220M/335M [00:02<00:01, 94.0MB/s]\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:   6% 199M/3.44G [00:02<00:36, 87.7MB/s]\u001b[A\u001b[A\u001b[A\n","model.safetensors:  38% 189M/492M [00:02<00:04, 72.8MB/s]\u001b[A\n","\n","diffusion_pytorch_model.safetensors:  69% 231M/335M [00:02<00:01, 93.4MB/s]\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:   6% 210M/3.44G [00:02<00:36, 87.7MB/s]\u001b[A\u001b[A\u001b[A\n","\n","diffusion_pytorch_model.safetensors:  72% 241M/335M [00:02<00:00, 94.3MB/s]\u001b[A\u001b[A\n","model.safetensors:  40% 199M/492M [00:02<00:03, 74.3MB/s]\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:   6% 220M/3.44G [00:02<00:36, 88.2MB/s]\u001b[A\u001b[A\u001b[A\n","\n","diffusion_pytorch_model.safetensors:  75% 252M/335M [00:02<00:00, 96.4MB/s]\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:   7% 231M/3.44G [00:02<00:34, 92.4MB/s]\u001b[A\u001b[A\u001b[A\n","model.safetensors:  43% 210M/492M [00:03<00:03, 73.1MB/s]\u001b[A\n","\n","diffusion_pytorch_model.safetensors:  78% 262M/335M [00:02<00:00, 97.1MB/s]\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:   7% 241M/3.44G [00:03<00:34, 93.6MB/s]\u001b[A\u001b[A\u001b[A\n","model.safetensors:  45% 220M/492M [00:03<00:03, 72.7MB/s]\u001b[A\n","\n","diffusion_pytorch_model.safetensors:  81% 273M/335M [00:03<00:00, 93.3MB/s]\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:   7% 252M/3.44G [00:03<00:36, 88.1MB/s]\u001b[A\u001b[A\u001b[A\n","model.safetensors:  47% 231M/492M [00:03<00:03, 72.2MB/s]\u001b[A\n","\n","diffusion_pytorch_model.safetensors:  85% 283M/335M [00:03<00:00, 89.9MB/s]\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:   8% 262M/3.44G [00:03<00:34, 91.2MB/s]\u001b[A\u001b[A\u001b[A\n","\n","diffusion_pytorch_model.safetensors:  88% 294M/335M [00:03<00:00, 93.6MB/s]\u001b[A\u001b[A\n","model.safetensors:  49% 241M/492M [00:03<00:03, 72.0MB/s]\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:   8% 273M/3.44G [00:03<00:34, 92.0MB/s]\u001b[A\u001b[A\u001b[A\n","\n","diffusion_pytorch_model.safetensors:  91% 304M/335M [00:03<00:00, 92.4MB/s]\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:   8% 283M/3.44G [00:03<00:35, 89.9MB/s]\u001b[A\u001b[A\u001b[A\n","model.safetensors:  51% 252M/492M [00:03<00:03, 71.7MB/s]\u001b[A\n","\n","diffusion_pytorch_model.safetensors:  94% 315M/335M [00:03<00:00, 94.0MB/s]\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:   9% 294M/3.44G [00:03<00:34, 90.6MB/s]\u001b[A\u001b[A\u001b[A\n","model.safetensors:  53% 262M/492M [00:03<00:03, 73.3MB/s]\u001b[A\n","\n","diffusion_pytorch_model.safetensors:  97% 325M/335M [00:03<00:00, 93.5MB/s]\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:   9% 304M/3.44G [00:03<00:34, 91.6MB/s]\u001b[A\u001b[A\u001b[A\n","\n","diffusion_pytorch_model.safetensors: 100% 335M/335M [00:03<00:00, 90.0MB/s]\u001b[A\u001b[A\n","diffusion_pytorch_model.safetensors: 100% 335M/335M [00:03<00:00, 88.4MB/s]\n","\n","\n","\n","diffusion_pytorch_model.safetensors:   9% 315M/3.44G [00:03<00:35, 88.9MB/s]\u001b[A\u001b[A\u001b[A\n","model.safetensors:  58% 283M/492M [00:04<00:02, 72.1MB/s]\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:   9% 325M/3.44G [00:03<00:34, 91.3MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  10% 336M/3.44G [00:04<00:33, 93.0MB/s]\u001b[A\u001b[A\u001b[A\n","model.safetensors:  60% 294M/492M [00:04<00:02, 71.0MB/s]\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  10% 346M/3.44G [00:04<00:32, 95.5MB/s]\u001b[A\u001b[A\u001b[A\n","model.safetensors:  62% 304M/492M [00:04<00:02, 71.2MB/s]\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  10% 357M/3.44G [00:04<00:31, 97.2MB/s]\u001b[A\u001b[A\u001b[A\n","model.safetensors:  64% 315M/492M [00:04<00:02, 74.0MB/s]\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  11% 367M/3.44G [00:04<00:31, 97.8MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  11% 377M/3.44G [00:04<00:35, 87.2MB/s]\u001b[A\u001b[A\u001b[A\n","model.safetensors:  66% 325M/492M [00:04<00:02, 70.3MB/s]\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  11% 388M/3.44G [00:04<00:34, 87.2MB/s]\u001b[A\u001b[A\u001b[A\n","model.safetensors:  68% 336M/492M [00:04<00:02, 71.0MB/s]\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  12% 398M/3.44G [00:04<00:33, 91.0MB/s]\u001b[A\u001b[A\u001b[A\n","model.safetensors:  70% 346M/492M [00:04<00:02, 72.9MB/s]\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  12% 409M/3.44G [00:04<00:35, 85.3MB/s]\u001b[A\u001b[A\u001b[A\n","model.safetensors:  72% 357M/492M [00:05<00:01, 71.6MB/s]\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  12% 419M/3.44G [00:05<00:36, 82.6MB/s]\u001b[A\u001b[A\u001b[A\n","model.safetensors:  75% 367M/492M [00:05<00:01, 71.9MB/s]\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  13% 430M/3.44G [00:05<00:38, 77.5MB/s]\u001b[A\u001b[A\u001b[A\n","model.safetensors:  77% 377M/492M [00:05<00:01, 70.8MB/s]\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  13% 440M/3.44G [00:05<00:37, 79.0MB/s]\u001b[A\u001b[A\u001b[A\n","model.safetensors:  79% 388M/492M [00:05<00:01, 73.5MB/s]\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  13% 451M/3.44G [00:05<00:35, 83.9MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  13% 461M/3.44G [00:05<00:33, 88.2MB/s]\u001b[A\u001b[A\u001b[A\n","model.safetensors:  81% 398M/492M [00:05<00:01, 73.5MB/s]\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  14% 472M/3.44G [00:05<00:32, 90.8MB/s]\u001b[A\u001b[A\u001b[A\n","model.safetensors:  83% 409M/492M [00:05<00:01, 72.1MB/s]\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  14% 482M/3.44G [00:05<00:34, 86.2MB/s]\u001b[A\u001b[A\u001b[A\n","model.safetensors:  85% 419M/492M [00:06<00:01, 72.5MB/s]\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  14% 493M/3.44G [00:05<00:32, 90.5MB/s]\u001b[A\u001b[A\u001b[A\n","model.safetensors:  87% 430M/492M [00:06<00:00, 75.0MB/s]\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  15% 503M/3.44G [00:05<00:32, 90.1MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  15% 514M/3.44G [00:06<00:31, 93.6MB/s]\u001b[A\u001b[A\u001b[A\n","model.safetensors:  89% 440M/492M [00:06<00:00, 76.6MB/s]\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  15% 524M/3.44G [00:06<00:31, 93.7MB/s]\u001b[A\u001b[A\u001b[A\n","model.safetensors:  92% 451M/492M [00:06<00:00, 76.7MB/s]\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  16% 535M/3.44G [00:06<00:30, 94.9MB/s]\u001b[A\u001b[A\u001b[A\n","model.safetensors:  94% 461M/492M [00:06<00:00, 75.0MB/s]\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  16% 545M/3.44G [00:06<00:31, 91.9MB/s]\u001b[A\u001b[A\u001b[A\n","model.safetensors:  96% 472M/492M [00:06<00:00, 72.3MB/s]\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  16% 556M/3.44G [00:06<00:32, 88.6MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  16% 566M/3.44G [00:06<00:31, 90.7MB/s]\u001b[A\u001b[A\u001b[A\n","model.safetensors:  98% 482M/492M [00:06<00:00, 71.6MB/s]\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  17% 577M/3.44G [00:06<00:30, 92.9MB/s]\u001b[A\u001b[A\u001b[A\n","model.safetensors: 100% 492M/492M [00:07<00:00, 71.1MB/s]\u001b[A\n","\n","\n","model.safetensors: 100% 492M/492M [00:09<00:00, 53.5MB/s]\n","Fetching 13 files:  38% 5/13 [00:09<00:16,  2.01s/it]\n","\n","\n","diffusion_pytorch_model.safetensors:  17% 598M/3.44G [00:09<04:18, 11.0MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  18% 619M/3.44G [00:09<02:30, 18.8MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  19% 640M/3.44G [00:10<01:40, 27.9MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  19% 661M/3.44G [00:10<01:12, 38.2MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  20% 682M/3.44G [00:10<00:56, 49.1MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  20% 692M/3.44G [00:10<00:50, 54.5MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  21% 713M/3.44G [00:10<00:41, 65.5MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  21% 734M/3.44G [00:11<00:35, 75.3MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  22% 755M/3.44G [00:11<00:32, 83.5MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  23% 776M/3.44G [00:11<00:29, 89.8MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  23% 786M/3.44G [00:11<00:28, 92.0MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  23% 807M/3.44G [00:11<00:27, 96.5MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  24% 818M/3.44G [00:11<00:26, 97.9MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  24% 828M/3.44G [00:11<00:26, 97.9MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  24% 839M/3.44G [00:12<00:26, 99.2MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  25% 849M/3.44G [00:12<00:25, 100MB/s] \u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  25% 860M/3.44G [00:12<00:25, 100MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  25% 870M/3.44G [00:12<00:25, 101MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  26% 891M/3.44G [00:12<00:24, 103MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  27% 912M/3.44G [00:12<00:24, 105MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  27% 933M/3.44G [00:12<00:23, 106MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  28% 954M/3.44G [00:13<00:23, 106MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  28% 975M/3.44G [00:13<00:23, 106MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  29% 996M/3.44G [00:13<00:23, 105MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  29% 1.01G/3.44G [00:13<00:23, 104MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  30% 1.03G/3.44G [00:13<00:23, 104MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  30% 1.05G/3.44G [00:14<00:23, 99.7MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  31% 1.06G/3.44G [00:14<00:23, 99.7MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  31% 1.07G/3.44G [00:14<00:30, 76.8MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  31% 1.08G/3.44G [00:14<00:28, 81.4MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  32% 1.10G/3.44G [00:14<00:26, 89.4MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  32% 1.11G/3.44G [00:14<00:25, 92.2MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  33% 1.13G/3.44G [00:15<00:23, 96.6MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  33% 1.14G/3.44G [00:15<00:23, 97.4MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  34% 1.15G/3.44G [00:15<00:34, 65.7MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  34% 1.17G/3.44G [00:15<00:29, 76.6MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  34% 1.18G/3.44G [00:15<00:27, 81.3MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  35% 1.21G/3.44G [00:16<00:24, 89.8MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  36% 1.23G/3.44G [00:16<00:23, 95.5MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  36% 1.25G/3.44G [00:16<00:21, 99.6MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  37% 1.26G/3.44G [00:16<00:21, 100MB/s] \u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  37% 1.27G/3.44G [00:16<00:21, 100MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  37% 1.28G/3.44G [00:16<00:21, 101MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  38% 1.30G/3.44G [00:16<00:20, 102MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  38% 1.32G/3.44G [00:17<00:20, 103MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  39% 1.34G/3.44G [00:17<00:19, 105MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  40% 1.36G/3.44G [00:17<00:19, 106MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  40% 1.38G/3.44G [00:17<00:19, 105MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  41% 1.41G/3.44G [00:17<00:19, 104MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  41% 1.42G/3.44G [00:17<00:19, 104MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  41% 1.43G/3.44G [00:18<00:20, 98.3MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  42% 1.44G/3.44G [00:18<00:21, 95.1MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  42% 1.45G/3.44G [00:18<00:21, 92.7MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  42% 1.46G/3.44G [00:18<00:21, 91.5MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  43% 1.47G/3.44G [00:18<00:20, 94.0MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  43% 1.48G/3.44G [00:18<00:21, 93.1MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  43% 1.49G/3.44G [00:18<00:20, 96.0MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  44% 1.50G/3.44G [00:18<00:19, 98.1MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  44% 1.51G/3.44G [00:19<00:43, 44.4MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  44% 1.52G/3.44G [00:19<00:36, 53.0MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  45% 1.53G/3.44G [00:19<00:31, 60.9MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  45% 1.54G/3.44G [00:19<00:27, 67.8MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  45% 1.55G/3.44G [00:19<00:25, 74.6MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  45% 1.56G/3.44G [00:19<00:23, 81.2MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  46% 1.57G/3.44G [00:20<00:21, 86.7MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  46% 1.58G/3.44G [00:20<00:20, 90.8MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  46% 1.59G/3.44G [00:20<00:19, 94.1MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  47% 1.60G/3.44G [00:20<00:19, 94.1MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  47% 1.63G/3.44G [00:20<00:17, 101MB/s] \u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  48% 1.64G/3.44G [00:20<00:17, 101MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  48% 1.65G/3.44G [00:20<00:18, 98.6MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  48% 1.66G/3.44G [00:20<00:18, 98.8MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  48% 1.67G/3.44G [00:21<00:17, 99.2MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  49% 1.68G/3.44G [00:21<00:17, 99.6MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  49% 1.69G/3.44G [00:21<00:17, 100MB/s] \u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  49% 1.70G/3.44G [00:21<00:17, 100MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  50% 1.72G/3.44G [00:21<00:16, 103MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  51% 1.74G/3.44G [00:21<00:16, 105MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  51% 1.76G/3.44G [00:21<00:15, 106MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  52% 1.78G/3.44G [00:22<00:15, 107MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  52% 1.80G/3.44G [00:22<00:15, 105MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  53% 1.82G/3.44G [00:22<00:15, 105MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  53% 1.84G/3.44G [00:22<00:15, 104MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  54% 1.85G/3.44G [00:22<00:15, 103MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  54% 1.86G/3.44G [00:22<00:15, 103MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  54% 1.87G/3.44G [00:22<00:15, 103MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  55% 1.88G/3.44G [00:23<00:16, 95.5MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  55% 1.89G/3.44G [00:23<00:16, 91.5MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  55% 1.90G/3.44G [00:25<01:51, 13.8MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  56% 1.91G/3.44G [00:26<01:42, 14.9MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  56% 1.93G/3.44G [00:26<01:01, 24.4MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  57% 1.95G/3.44G [00:26<00:42, 35.1MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  57% 1.97G/3.44G [00:26<00:31, 46.3MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  58% 1.99G/3.44G [00:26<00:25, 57.6MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  58% 2.00G/3.44G [00:27<00:22, 62.7MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  59% 2.01G/3.44G [00:27<00:21, 67.5MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  59% 2.02G/3.44G [00:27<00:19, 73.5MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  59% 2.03G/3.44G [00:27<00:17, 78.9MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  60% 2.06G/3.44G [00:27<00:15, 88.3MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  60% 2.08G/3.44G [00:27<00:14, 95.1MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  61% 2.10G/3.44G [00:27<00:13, 99.7MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  62% 2.12G/3.44G [00:28<00:12, 103MB/s] \u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  62% 2.14G/3.44G [00:28<00:12, 104MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  63% 2.16G/3.44G [00:28<00:12, 103MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  63% 2.18G/3.44G [00:28<00:12, 103MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  64% 2.19G/3.44G [00:28<00:12, 103MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  64% 2.20G/3.44G [00:28<00:12, 103MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  65% 2.22G/3.44G [00:29<00:18, 67.3MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  65% 2.23G/3.44G [00:29<00:16, 72.2MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  65% 2.24G/3.44G [00:29<00:15, 77.5MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  66% 2.25G/3.44G [00:29<00:14, 82.5MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  66% 2.26G/3.44G [00:29<00:13, 87.1MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  66% 2.29G/3.44G [00:30<00:12, 95.2MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  67% 2.30G/3.44G [00:30<00:11, 96.9MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  67% 2.32G/3.44G [00:30<00:11, 101MB/s] \u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  68% 2.33G/3.44G [00:30<00:10, 101MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  68% 2.34G/3.44G [00:30<00:10, 102MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  69% 2.36G/3.44G [00:30<00:10, 103MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  69% 2.38G/3.44G [00:30<00:10, 104MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  70% 2.40G/3.44G [00:31<00:10, 102MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  70% 2.41G/3.44G [00:31<00:10, 101MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  70% 2.42G/3.44G [00:31<00:10, 101MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  71% 2.43G/3.44G [00:31<00:10, 98.5MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  71% 2.44G/3.44G [00:31<00:10, 98.2MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  71% 2.45G/3.44G [00:31<00:09, 99.5MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  72% 2.46G/3.44G [00:31<00:09, 101MB/s] \u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  72% 2.49G/3.44G [00:31<00:09, 103MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  73% 2.50G/3.44G [00:32<00:09, 103MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  73% 2.51G/3.44G [00:32<00:09, 102MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  73% 2.52G/3.44G [00:34<01:05, 14.1MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  74% 2.53G/3.44G [00:35<00:56, 16.2MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  74% 2.54G/3.44G [00:37<01:30, 9.97MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  74% 2.55G/3.44G [00:37<01:10, 12.7MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  74% 2.56G/3.44G [00:37<00:54, 16.2MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  75% 2.57G/3.44G [00:37<00:41, 20.9MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  75% 2.58G/3.44G [00:37<00:31, 27.1MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  75% 2.59G/3.44G [00:38<00:24, 34.3MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  76% 2.60G/3.44G [00:38<00:19, 42.9MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  76% 2.62G/3.44G [00:38<00:13, 59.6MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  77% 2.63G/3.44G [00:38<00:12, 66.6MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  77% 2.64G/3.44G [00:38<00:10, 73.1MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  77% 2.65G/3.44G [00:38<00:09, 79.4MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  77% 2.66G/3.44G [00:38<00:09, 84.8MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  78% 2.67G/3.44G [00:38<00:08, 89.4MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  78% 2.68G/3.44G [00:38<00:08, 93.0MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  79% 2.71G/3.44G [00:39<00:07, 98.5MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  79% 2.72G/3.44G [00:39<00:07, 99.8MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  80% 2.74G/3.44G [00:39<00:06, 104MB/s] \u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  80% 2.76G/3.44G [00:39<00:06, 105MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  81% 2.78G/3.44G [00:39<00:06, 105MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  81% 2.80G/3.44G [00:40<00:06, 105MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  82% 2.82G/3.44G [00:40<00:05, 106MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  83% 2.84G/3.44G [00:40<00:05, 106MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  83% 2.86G/3.44G [00:40<00:05, 107MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  84% 2.88G/3.44G [00:40<00:05, 107MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  84% 2.90G/3.44G [00:41<00:05, 106MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  85% 2.93G/3.44G [00:41<00:04, 107MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  86% 2.95G/3.44G [00:41<00:04, 108MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  86% 2.97G/3.44G [00:41<00:04, 107MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  87% 2.99G/3.44G [00:41<00:04, 107MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  88% 3.01G/3.44G [00:41<00:04, 106MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  88% 3.03G/3.44G [00:42<00:03, 105MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  89% 3.05G/3.44G [00:42<00:03, 101MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  89% 3.07G/3.44G [00:42<00:03, 103MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  90% 3.09G/3.44G [00:42<00:03, 104MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  91% 3.11G/3.44G [00:43<00:03, 106MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  91% 3.14G/3.44G [00:43<00:02, 107MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  92% 3.16G/3.44G [00:43<00:02, 102MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  92% 3.17G/3.44G [00:43<00:02, 102MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  92% 3.18G/3.44G [00:43<00:02, 99.4MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  93% 3.19G/3.44G [00:43<00:02, 97.4MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  93% 3.20G/3.44G [00:43<00:02, 96.7MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  93% 3.21G/3.44G [00:43<00:02, 95.5MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  94% 3.22G/3.44G [00:44<00:02, 97.5MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  94% 3.23G/3.44G [00:44<00:02, 99.0MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  94% 3.24G/3.44G [00:44<00:01, 99.6MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  95% 3.25G/3.44G [00:45<00:09, 18.8MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  95% 3.26G/3.44G [00:46<00:10, 17.5MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  95% 3.28G/3.44G [00:46<00:05, 28.2MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  96% 3.30G/3.44G [00:47<00:03, 39.8MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  97% 3.32G/3.44G [00:47<00:02, 51.3MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  97% 3.34G/3.44G [00:47<00:01, 62.6MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  98% 3.36G/3.44G [00:47<00:01, 67.5MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  98% 3.37G/3.44G [00:47<00:00, 73.1MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  99% 3.39G/3.44G [00:47<00:00, 82.6MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  99% 3.40G/3.44G [00:47<00:00, 86.3MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors:  99% 3.42G/3.44G [00:48<00:00, 93.3MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","diffusion_pytorch_model.safetensors: 100% 3.44G/3.44G [00:48<00:00, 71.1MB/s]\n","Fetching 13 files: 100% 13/13 [00:48<00:00,  3.76s/it]\n","{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n","Loading pipeline components...:   0% 0/6 [00:00<?, ?it/s]Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.\n","Loading pipeline components...:  17% 1/6 [00:00<00:00,  7.76it/s]Instantiating AutoencoderKL model under default dtype torch.float16.\n","{'shift_factor', 'mid_block_add_attention', 'latents_mean', 'scaling_factor', 'latents_std', 'use_post_quant_conv', 'use_quant_conv', 'force_upcast'} was not found in config. Values will be initialized to default values.\n","All model checkpoint weights were used when initializing AutoencoderKL.\n","\n","All the weights of AutoencoderKL were initialized from the model checkpoint at /root/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.\n","Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.\n","Loading pipeline components...:  33% 2/6 [00:02<00:04,  1.18s/it]Instantiating UNet2DConditionModel model under default dtype torch.float16.\n","{'use_linear_projection', 'class_embed_type', 'num_attention_heads', 'num_class_embeds', 'dual_cross_attention', 'mid_block_type', 'conv_in_kernel', 'time_embedding_type', 'projection_class_embeddings_input_dim', 'encoder_hid_dim_type', 'resnet_out_scale_factor', 'only_cross_attention', 'mid_block_only_cross_attention', 'addition_time_embed_dim', 'resnet_time_scale_shift', 'class_embeddings_concat', 'upcast_attention', 'addition_embed_type_num_heads', 'time_cond_proj_dim', 'timestep_post_act', 'time_embedding_act_fn', 'attention_type', 'transformer_layers_per_block', 'dropout', 'conv_out_kernel', 'reverse_transformer_layers_per_block', 'addition_embed_type', 'time_embedding_dim', 'cross_attention_norm', 'encoder_hid_dim', 'resnet_skip_time_act'} was not found in config. Values will be initialized to default values.\n","All model checkpoint weights were used when initializing UNet2DConditionModel.\n","\n","All the weights of UNet2DConditionModel were initialized from the model checkpoint at /root/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/unet.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use UNet2DConditionModel for predictions without further training.\n","Loaded unet as UNet2DConditionModel from `unet` subfolder of runwayml/stable-diffusion-v1-5.\n","Loading pipeline components...:  50% 3/6 [00:17<00:22,  7.49s/it]{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n","Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n","Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n","Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.\n","Loading pipeline components...: 100% 6/6 [00:19<00:00,  3.20s/it]\n","You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n","You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n","{'clip_sample_range', 'prediction_type', 'variance_type', 'rescale_betas_zero_snr', 'dynamic_thresholding_ratio', 'sample_max_value', 'timestep_spacing', 'thresholding'} was not found in config. Values will be initialized to default values.\n","{'shift_factor', 'mid_block_add_attention', 'latents_mean', 'scaling_factor', 'latents_std', 'use_post_quant_conv', 'use_quant_conv', 'force_upcast'} was not found in config. Values will be initialized to default values.\n","All model checkpoint weights were used when initializing AutoencoderKL.\n","\n","All the weights of AutoencoderKL were initialized from the model checkpoint at runwayml/stable-diffusion-v1-5.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.\n","{'use_linear_projection', 'class_embed_type', 'num_attention_heads', 'num_class_embeds', 'dual_cross_attention', 'mid_block_type', 'conv_in_kernel', 'time_embedding_type', 'projection_class_embeddings_input_dim', 'encoder_hid_dim_type', 'resnet_out_scale_factor', 'only_cross_attention', 'mid_block_only_cross_attention', 'addition_time_embed_dim', 'resnet_time_scale_shift', 'class_embeddings_concat', 'upcast_attention', 'addition_embed_type_num_heads', 'time_cond_proj_dim', 'timestep_post_act', 'time_embedding_act_fn', 'attention_type', 'transformer_layers_per_block', 'dropout', 'conv_out_kernel', 'reverse_transformer_layers_per_block', 'addition_embed_type', 'time_embedding_dim', 'cross_attention_norm', 'encoder_hid_dim', 'resnet_skip_time_act'} was not found in config. Values will be initialized to default values.\n","All model checkpoint weights were used when initializing UNet2DConditionModel.\n","\n","All the weights of UNet2DConditionModel were initialized from the model checkpoint at runwayml/stable-diffusion-v1-5.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use UNet2DConditionModel for predictions without further training.\n","Steps:  50% 2000/4000 [50:36<48:13,  1.45s/it, loss=0.467, lr=2e-6]Configuration saved in /content/drive/MyDrive/oldbookillustrations-dataset/model_output/checkpoint-2000/unet/config.json\n","Model weights saved in /content/drive/MyDrive/oldbookillustrations-dataset/model_output/checkpoint-2000/unet/diffusion_pytorch_model.safetensors\n","Steps: 100% 4000/4000 [1:41:36<00:00,  1.43s/it, loss=0.042, lr=2e-6]Configuration saved in /content/drive/MyDrive/oldbookillustrations-dataset/model_output/checkpoint-4000/unet/config.json\n","Model weights saved in /content/drive/MyDrive/oldbookillustrations-dataset/model_output/checkpoint-4000/unet/diffusion_pytorch_model.safetensors\n","Steps: 100% 4000/4000 [1:42:27<00:00,  1.43s/it, loss=0.262, lr=2e-6]\n","Fetching 11 files:   0% 0/11 [00:00<?, ?it/s]\u001b[A\n","\n","config.json: 4.72kB [00:00, 18.6MB/s]\n","\n","Fetching 11 files:  27% 3/11 [00:00<00:00, 11.01it/s]\u001b[A\n","\n","model.safetensors:   0% 0.00/1.22G [00:00<?, ?B/s]\u001b[A\u001b[A\n","\n","model.safetensors:   1% 10.5M/1.22G [00:00<00:42, 28.7MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:   2% 21.0M/1.22G [00:00<00:25, 46.1MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:   3% 41.9M/1.22G [00:00<00:13, 88.9MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:   5% 62.9M/1.22G [00:00<00:09, 116MB/s] \u001b[A\u001b[A\n","\n","model.safetensors:   7% 83.9M/1.22G [00:00<00:09, 115MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:   9% 105M/1.22G [00:01<00:10, 103MB/s] \u001b[A\u001b[A\n","\n","model.safetensors:  10% 126M/1.22G [00:01<00:10, 104MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  12% 147M/1.22G [00:01<00:10, 106MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  14% 168M/1.22G [00:01<00:08, 119MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  16% 189M/1.22G [00:02<00:11, 89.2MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  17% 210M/1.22G [00:07<01:25, 11.8MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  19% 231M/1.22G [00:07<01:00, 16.4MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  21% 252M/1.22G [00:07<00:43, 22.3MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  22% 273M/1.22G [00:07<00:31, 30.0MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  24% 294M/1.22G [00:07<00:23, 39.4MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  26% 315M/1.22G [00:08<00:18, 48.9MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  28% 336M/1.22G [00:08<00:15, 56.2MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  29% 357M/1.22G [00:08<00:13, 61.6MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  30% 367M/1.22G [00:08<00:13, 63.6MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  31% 377M/1.22G [00:08<00:13, 63.8MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  32% 388M/1.22G [00:08<00:12, 66.3MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  34% 409M/1.22G [00:09<00:09, 86.6MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  35% 430M/1.22G [00:13<01:01, 12.9MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  36% 440M/1.22G [00:13<00:50, 15.3MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  37% 451M/1.22G [00:13<00:41, 18.3MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  38% 461M/1.22G [00:13<00:34, 21.8MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  39% 472M/1.22G [00:13<00:28, 26.1MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  40% 482M/1.22G [00:14<00:23, 30.7MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  41% 493M/1.22G [00:14<00:20, 35.7MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  41% 503M/1.22G [00:14<00:17, 41.5MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  42% 514M/1.22G [00:14<00:14, 50.1MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  43% 524M/1.22G [00:14<00:12, 56.4MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  44% 535M/1.22G [00:14<00:11, 61.5MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  45% 545M/1.22G [00:14<00:10, 66.1MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  46% 556M/1.22G [00:15<00:08, 74.3MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  47% 566M/1.22G [00:15<00:08, 74.8MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  47% 577M/1.22G [00:15<00:09, 67.6MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  48% 587M/1.22G [00:15<00:09, 66.3MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  49% 598M/1.22G [00:15<00:08, 71.1MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  50% 608M/1.22G [00:15<00:08, 74.5MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  51% 619M/1.22G [00:16<00:09, 60.0MB/s]\u001b[A\u001b[A\n","Fetching 11 files:  27% 3/11 [00:16<00:00, 11.01it/s]\u001b[A\n","\n","model.safetensors:  52% 629M/1.22G [00:16<00:09, 60.5MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  53% 650M/1.22G [00:16<00:07, 74.2MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  54% 661M/1.22G [00:21<01:10, 7.85MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  55% 671M/1.22G [00:21<00:53, 10.2MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  56% 682M/1.22G [00:21<00:40, 13.3MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  57% 692M/1.22G [00:21<00:30, 17.2MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  58% 703M/1.22G [00:22<00:23, 21.8MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  59% 713M/1.22G [00:22<00:18, 27.2MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  60% 724M/1.22G [00:22<00:15, 31.8MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  60% 734M/1.22G [00:22<00:13, 36.0MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  61% 744M/1.22G [00:22<00:11, 41.5MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  62% 755M/1.22G [00:22<00:09, 46.6MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  63% 765M/1.22G [00:23<00:08, 52.4MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  64% 776M/1.22G [00:23<00:07, 55.5MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  65% 786M/1.22G [00:23<00:07, 57.1MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  66% 797M/1.22G [00:23<00:06, 60.0MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  66% 807M/1.22G [00:23<00:06, 62.9MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  67% 818M/1.22G [00:23<00:06, 63.1MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  68% 828M/1.22G [00:23<00:06, 63.1MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  69% 839M/1.22G [00:24<00:05, 64.3MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  70% 849M/1.22G [00:24<00:05, 64.8MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  71% 860M/1.22G [00:24<00:06, 57.0MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  72% 870M/1.22G [00:25<00:15, 22.8MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  73% 891M/1.22G [00:25<00:09, 34.7MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  74% 902M/1.22G [00:26<00:07, 39.4MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  75% 912M/1.22G [00:26<00:09, 32.3MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  76% 923M/1.22G [00:26<00:07, 37.8MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  77% 933M/1.22G [00:26<00:06, 43.2MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  78% 944M/1.22G [00:26<00:05, 49.1MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  78% 954M/1.22G [00:27<00:04, 55.1MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  80% 975M/1.22G [00:27<00:03, 72.0MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  81% 986M/1.22G [00:27<00:03, 74.1MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  82% 996M/1.22G [00:27<00:02, 74.9MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  83% 1.01G/1.22G [00:27<00:03, 68.7MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  84% 1.02G/1.22G [00:27<00:02, 68.5MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  85% 1.03G/1.22G [00:28<00:02, 67.0MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  85% 1.04G/1.22G [00:28<00:02, 66.6MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  86% 1.05G/1.22G [00:28<00:02, 70.4MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  87% 1.06G/1.22G [00:28<00:02, 76.8MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  88% 1.07G/1.22G [00:28<00:02, 67.2MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  89% 1.08G/1.22G [00:28<00:01, 70.6MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  91% 1.10G/1.22G [00:29<00:01, 76.4MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  91% 1.11G/1.22G [00:33<00:12, 8.35MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  92% 1.12G/1.22G [00:33<00:08, 10.8MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  93% 1.13G/1.22G [00:34<00:05, 14.0MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  94% 1.14G/1.22G [00:34<00:04, 18.0MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  95% 1.15G/1.22G [00:34<00:02, 22.6MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  96% 1.16G/1.22G [00:34<00:01, 27.3MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  97% 1.17G/1.22G [00:34<00:01, 31.7MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  97% 1.18G/1.22G [00:34<00:00, 35.2MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  98% 1.20G/1.22G [00:35<00:00, 39.1MB/s]\u001b[A\u001b[A\n","\n","model.safetensors:  99% 1.21G/1.22G [00:35<00:00, 44.0MB/s]\u001b[A\u001b[A\n","\n","model.safetensors: 100% 1.22G/1.22G [00:35<00:00, 34.2MB/s]\n","\n","Fetching 11 files: 100% 11/11 [00:35<00:00,  3.26s/it]\n","{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n","\n","Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.\n","\n","Loading pipeline components...:  14% 1/7 [00:00<00:01,  5.50it/s]\u001b[ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n","\n","Loading pipeline components...:  29% 2/7 [00:01<00:05,  1.02s/it]\u001b[A{'shift_factor', 'mid_block_add_attention', 'latents_mean', 'scaling_factor', 'latents_std', 'use_post_quant_conv', 'use_quant_conv', 'force_upcast'} was not found in config. Values will be initialized to default values.\n","All model checkpoint weights were used when initializing AutoencoderKL.\n","\n","All the weights of AutoencoderKL were initialized from the model checkpoint at /root/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.\n","Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.\n","\n","Loading pipeline components...:  43% 3/7 [00:02<00:03,  1.25it/s]\u001b[A{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n","Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n","Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n","Loading pipeline components...: 100% 7/7 [00:02<00:00,  2.94it/s]\n","{'timestep_spacing', 'prediction_type'} was not found in config. Values will be initialized to default values.\n","Configuration saved in /content/drive/MyDrive/oldbookillustrations-dataset/model_output/vae/config.json\n","Model weights saved in /content/drive/MyDrive/oldbookillustrations-dataset/model_output/vae/diffusion_pytorch_model.safetensors\n","Configuration saved in /content/drive/MyDrive/oldbookillustrations-dataset/model_output/unet/config.json\n","Model weights saved in /content/drive/MyDrive/oldbookillustrations-dataset/model_output/unet/diffusion_pytorch_model.safetensors\n","Configuration saved in /content/drive/MyDrive/oldbookillustrations-dataset/model_output/scheduler/scheduler_config.json\n","Configuration saved in /content/drive/MyDrive/oldbookillustrations-dataset/model_output/model_index.json\n","Steps: 100% 4000/4000 [1:44:56<00:00,  1.57s/it, loss=0.262, lr=2e-6]\n"]}]},{"cell_type":"code","source":["from diffusers import StableDiffusionPipeline\n","import torch\n","from IPython.display import display\n","\n","model_dir = \"/content/drive/MyDrive/oldbookillustrations-dataset/model_output\"\n","\n","pipe = StableDiffusionPipeline.from_pretrained(\n","    model_dir,\n","    torch_dtype=torch.float16,\n",").to(\"cuda\")\n","\n","prompts = [\n","    \"a vintage woodcut of [V*] a knight with a sword riding a horse, 16th century engraving\",\n","    \"an antique illustration of [V*] a dragon flying over a castle, woodcut style\",\n","    \"a medieval etching of [V*] a queen wearing a crown and royal robe\",\n","    \"a 17th century book illustration of [V*] a sea monster attacking a ship\",\n","    \"a detailed ink drawing of [V*] a wizard casting a spell in a dark forest\",\n","    \" a red apple on the table\"\n","]\n","\n","for i, prompt in enumerate(prompts):\n","    print(f\"🎨 Generating image {i+1} from prompt:\\n{prompt}\\n\")\n","    image = pipe(prompt).images[0]\n","    display(image)  # ✅ Hiển thị trong Colab\n","    image.save(f\"/content/drive/MyDrive/oldbookillustrations-dataset/my_IMAGES/generated_image_{i+1}.png\")  # ✅ Lưu ảnh\n"],"metadata":{"id":"CgyhxilsBItB"},"execution_count":null,"outputs":[]}]}